{"cells":[{"cell_type":"markdown","metadata":{"id":"CpS1qNTfirYN"},"source":["Graph Neural Network with NetworkX - StellarGraph \n","\n","Algorithm Selection for the Travelling Salesman Problem"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5598,"status":"ok","timestamp":1648119053838,"user":{"displayName":"X Y","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05199952050475594564"},"user_tz":0},"id":"4DKy29nGkNs3","outputId":"19d92292-d3b4-4799-f10e-ac46c9033826"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 435 kB 32.2 MB/s \n","\u001b[K     |████████████████████████████████| 462 kB 64.9 MB/s \n","\u001b[?25h"]}],"source":["!pip install -q stellargraph"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OfOc7WgDkVn8"},"outputs":[],"source":["import os\n","import csv\n","import time \n","import math\n","import random\n","import numpy as np\n","import pandas as pd\n","import networkx as nx\n","import tensorflow as tf\n","import stellargraph as sg\n","from stellargraph import StellarGraph\n","from stellargraph.layer import DeepGraphCNN,GAT\n","from stellargraph.mapper import PaddedGraphGenerator\n","from stellargraph.layer import GCNSupervisedGraphClassification\n","\n","from sklearn.datasets import load_files\n","from sklearn.metrics import classification_report\n","from sklearn import model_selection, preprocessing\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.model_selection import KFold\n","from sklearn.neighbors import KDTree\n","\n","from tensorflow.keras import Model\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.layers import Dense, Conv1D,Conv2D, MaxPool1D, Dropout, Flatten\n","from tensorflow.keras.losses import binary_crossentropy,categorical_crossentropy\n"]},{"cell_type":"code","source":["!cp \"/content/drive/MyDrive/Colab Notebooks/GECCO-2022/All-6Set.zip\" \"/content/\""],"metadata":{"id":"2eHtcfM9C7l_"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lhRtif16k1zD"},"outputs":[],"source":["!mkdir \"/content/all\"\n","!unzip \"/content/All-6Set.zip\" -d \"/content/all\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HI-QVrjdkxwy"},"outputs":[],"source":["def extractTSPparams(file_path):\n","  instance = []\n","  lines = []\n","\n","  start = 0\n","  with open(file_path) as f:\n","    lines = f.read().splitlines()\n","    #print(lines)\n","  for i in range(start, len(lines)-1):\n","    line = lines[i].split(\",\")\n","    instance.append([float(line[0]),float(line[1])])\n","  #print(instance)\n","  return instance"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ii3YeuftY4O8"},"outputs":[],"source":["def extractKPparams(file_path):\n","  objects = []\n","  lines = []\n","\n","  start = 0\n","  with open(file_path) as f:\n","    lines = f.read().splitlines()\n","\n","  capacity = lines[start][0]\n","  for i in range(start+1, len(lines)-1):\n","    line = lines[i].split( )\n","    objects.append([int(line[0]),int(line[1])])\n","  #print(instance)\n","  return capacity, objects"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zhYh3f1wZMp1"},"outputs":[],"source":["def extractGCSynthicparams(file_path):\n","  instance = []\n","  lines = []\n","  #problem data start at line 0\n","  start = 0\n","  with open(file_path) as f:\n","    lines = f.read().splitlines()\n","\n","  for i in range(start, len(lines)-1):\n","    line = lines[i].split(\",\")\n","    instance.append([int(line[0]),int(line[1])])\n","  #print(instance)\n","  return instance"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jQ7IFHG3k4fc"},"outputs":[],"source":["rootdir = '/content/all/CHR/'\n","TSPinstances = []\n","TSPlabels = []\n","AllLabels = []\n","instances_num = 2500\n","\n","for dir,subdir,files in os.walk(rootdir):\n","  for file in files[:instances_num]:\n","\n","    file_path = os.path.join(rootdir, file)\n","    #print(file_path)\n","    instanceName = file[:-4]\n","    TSPinstance = (instanceName, extractTSPparams(file_path))\n","    #if TSPinstance[1] != []:\n","    if len(TSPinstance[1]) > 5:        \n","      TSPinstances.append(TSPinstance)\n","      TSPlabels.append(0)\n","      AllLabels.append(0)\n","    else:\n","      print(instanceName + \" has no vertex!\")\n","\n","rootdir = '/content/all/GREEDY/'\n","\n","for dir,subdir, files in os.walk(rootdir):\n","  for file in files[:instances_num]:\n","\n","    file_path = os.path.join(rootdir, file)\n","    \n","    instanceName = file[:-4]\n","    TSPinstance = (instanceName, extractTSPparams(file_path))\n","    #if TSPinstance[1] != []:  \n","    if len(TSPinstance[1]) > 5:           \n","      TSPinstances.append(TSPinstance)\n","      TSPlabels.append(0)\n","      AllLabels.append(0)\n","    else:\n","      print(instanceName + \" has no vertex!\")\n","TSPlabels = pd.DataFrame(TSPlabels)\n","\n","rootdir = '/content/all/Expknap/'\n","\n","KPinstances = []\n","KPlabels = []\n","\n","for dir,subdir,files in os.walk(rootdir):\n","  for file in files[:instances_num]:\n","\n","    file_path = os.path.join(rootdir, file)\n","    #print(file_path)\n","    instanceName = file[:-4]\n","    KP_capacity, KP_objects = extractKPparams(file_path)\n","    KPinstance = (instanceName, KP_capacity, KP_objects)\n","     \n","    KPinstances.append(KPinstance)\n","    KPlabels.append(1)\n","    AllLabels.append(1)\n","\n","rootdir = '/content/all/Combo/'\n","\n","for dir,subdir,files in os.walk(rootdir):\n","  for file in files[:instances_num]:\n","\n","    file_path = os.path.join(rootdir, file)\n","    #print(file_path)\n","    instanceName = file[:-4]\n","    KP_capacity, KP_objects = extractKPparams(file_path)\n","    KPinstance = (instanceName, KP_capacity, KP_objects)\n","     \n","    KPinstances.append(KPinstance)\n","    KPlabels.append(1)\n","    AllLabels.append(1)\n","\n","KP_labels = pd.DataFrame(KPlabels)\n","\n","rootdir = '/content/all/DSATUR/'\n","GCinstances = []\n","GClabels = []\n","instances_num = 2500\n","\n","for dir,subdir,files in os.walk(rootdir):\n","  for file in files[:instances_num]:\n","\n","    file_path = os.path.join(rootdir, file)\n","    #print(file_path)\n","    instanceName = file[:-4]\n","    GCinstance = (instanceName, extractGCSynthicparams(file_path))\n","    if GCinstance[1] != []:        \n","      GCinstances.append(GCinstance)\n","      GClabels.append(2)\n","      AllLabels.append(2)\n","    else:\n","      print(instanceName + \" has no edges!\")\n","\n","rootdir = '/content/all/LF/'\n","\n","for dir,subdir, files in os.walk(rootdir):\n","  for file in files[:instances_num]:\n","\n","    file_path = os.path.join(rootdir, file)\n","    \n","    instanceName = file[:-4]\n","    GCinstance = (instanceName, extractGCSynthicparams(file_path))\n","    if GCinstance[1] != []:        \n","      GCinstances.append(GCinstance)\n","      GClabels.append(2)\n","      AllLabels.append(2)\n","    else:\n","      print(instanceName + \" has no edges!\")\n","GClabels = pd.DataFrame(GClabels)\n"]},{"cell_type":"code","source":["AllLabels = pd.DataFrame(AllLabels)\n","target_encoding = preprocessing.LabelBinarizer()\n","target_encoding.fit_transform(AllLabels)\n","AllLabels = target_encoding.transform(AllLabels)"],"metadata":{"id":"82N6TynT80Li"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h3FAEM3hj3rR"},"outputs":[],"source":["KPinstances_norm = []\n","\n","for inst in KPinstances:\n","  a2 = [[i / sum(j) for i in j] for j in inst[2]]\n","  KPinstances_norm.append((inst[0],inst[1],a2))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eh723iXjk-Tj"},"outputs":[],"source":["instancesG = []\n","\n","counter = 0\n","for instance in TSPinstances:\n","  tempG = nx.Graph(name = instance[0])\n","  tree = KDTree(instance[1], leaf_size=2)  \n","  g = nx.Graph()\n","  for i in range(0,len(instance[1])): \n","    tempG.add_node(i, coord=instance[1][i])\n","    dist, ind = tree.query([[instance[1][i][0],instance[1][i][1]]] , k=5)  \n","    for j in ind[0][1:]:\n","      distance = math.sqrt(((instance[1][i][0]-instance[1][j][0])**2)+((instance[1][i][1]-instance[1][j][1])**2))\n","      tempG.add_edge(i,j, weight=distance)\n","      tempG.add_edge(j,i, weight=distance)\n","    #for j in range(i,len(instance[1])):\n","      #distance = math.sqrt(((instance[1][i][0]-instance[1][j][0])**2)+((instance[1][i][1]-instance[1][j][1])**2))\n","      #tempG.add_edge(i,j, weight=1)\n","      #tempG.add_edge(j,i, weight=1)   \n","  \n","  SG = StellarGraph.from_networkx(tempG, node_features=\"coord\")\n","  instancesG.append(SG)\n","\n","#instancesKP = []\n","#instancesKPNX = []\n","counter = 0\n","\n","for instance in KPinstances_norm:\n","  tempG = nx.Graph(name = instance[0])\n","  tempG.add_node(0, profitweight=[0,math.log(float(instance[1]))])\n","  for count, vals in enumerate(instance[2]):\n","    tempG.add_node(count+1, profitweight=[vals[0], vals[1]])\n","    tempG.add_edge(0, count+1)\n","\n","  #instancesKPNX.append(tempG)\n","  SG = StellarGraph.from_networkx(tempG, node_features=\"profitweight\")\n","  instancesG.append(SG)\n","  if(len(instance[1])==0):\n","    print(\"empty\")\n","    print(counter)\n","  counter = counter +1\n","\n","counter = 0\n","for instance in GCinstances:\n","  tempG = nx.Graph(name = instance[0])\n","  for count, vals in enumerate(instance[1]):    \n","    tempG.add_edge(vals[0], vals[1])\n","  for node in tempG.nodes:\n","    tempG.nodes[node][\"feature\"] = (tempG.degree[node],0)  ##padding\n","    #tempG.nodes[node][\"feature\"] = (1,)\n","  #instancesGCNX.append(tempG)\n","  SG = StellarGraph.from_networkx(tempG, node_features=\"feature\")\n","  instancesG.append(SG)\n","\n","\n","\n","generator = PaddedGraphGenerator(graphs=instancesG)\n","#ClusterNodeGenerator "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":424,"status":"ok","timestamp":1647872496689,"user":{"displayName":"X Y","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05199952050475594564"},"user_tz":0},"id":"HGK8FjonjjFV","outputId":"4ba0ede8-a212-4a46-e21a-a42deea0acfa"},"outputs":[{"name":"stdout","output_type":"stream","text":["[93 91 92 89]\n"]}],"source":["print(ind[0][1:])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lHMZxEKNrVvD"},"outputs":[],"source":["TSPinstances = []\n","GCinstances = []\n","KPinstances_norm = []\n","KPinstances = []\n","instancesG = []\n","files = []\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3ghqeprymjoS"},"outputs":[],"source":["def DGCNN(generator):\n","  model = DeepGraphCNN(\n","                 layer_sizes=[32, 32, 32, 1],\n","                 activations=[\"tanh\",\"tanh\", \"tanh\", \"tanh\"],\n","                 generator=generator,\n","                 k=32\n","    )\n","  x_inp, x_out = model.in_out_tensors()\n","\n","  x_out = Conv1D(filters=16, kernel_size=64, strides=64)(x_out)\n","  x_out = MaxPool1D(pool_size=1)(x_out)\n","  x_out = Conv1D(filters=32, kernel_size=8, strides=1)(x_out)\n","  x_out = Flatten()(x_out)\n","  x_out = Dense(units=258, activation=\"relu\")(x_out)\n","  x_out = Dropout(rate=0.5)(x_out)\n","  predictions = Dense(units=1, activation=\"sigmoid\")(x_out)\n","\n","  model = Model(inputs=x_inp, outputs=predictions)\n","  return model\n","\n","def GCN(generator):\n","    gc_model = GCNSupervisedGraphClassification(\n","        layer_sizes=[32, 32],\n","        activations=[\"relu\", \"relu\"],\n","        generator=generator,\n","        dropout=0.5,\n","    )\n","    x_inp, x_out = gc_model.in_out_tensors()\n","    predictions = Dense(units=32, activation=\"relu\")(x_out)\n","    predictions = Dense(units=16, activation=\"relu\")(predictions)\n","    #predictions = Dense(units=6, activation=\"sigmoid\")(predictions)\n","    predictions = Dense(units=3, activation=\"softmax\")(predictions)\n","    model = Model(inputs=x_inp, outputs=predictions)\n","    return model\n","\n","def GATmodel(generator):\n","  gat = GAT(\n","    layer_sizes=[32, 32],\n","    activations=[\"elu\", \"softmax\"],\n","    attn_heads=8,\n","    generator=generator,\n","    in_dropout=0.5,\n","    attn_dropout=0.5,\n","    normalize=None,\n","  )\n","  x_inp, x_out = gat.in_out_tensors()\n","  predictions = Dense(units=32, activation=\"relu\")(x_out)\n","  predictions = Dense(units=16, activation=\"relu\")(predictions)\n","  predictions = Dense(units=1, activation=\"sigmoid\")(predictions)\n","\n","  # Let's create the Keras model and prepare it for training\n","  model = Model(inputs=x_inp, outputs=predictions)\n","  return model\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lQ19583z7aCW"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MB-HYQtsoYFP"},"outputs":[],"source":["def train_fold(model, train_gen, test_gen, epochs):\n","    history = model.fit(\n","        train_gen, epochs=epochs, validation_data=test_gen, verbose=1\n","    )\n","    # calculate performance on the test data and return along with history\n","    test_metrics = model.evaluate(test_gen)\n","    test_acc = test_metrics\n","    #print(test_metrics)\n","    #print(test_gen)\n","    predicted_y = model.predict(test_gen)\n","    #print(predicted_y)\n","    return (history, test_acc, test_gen.targets,predicted_y)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v5LTz8xNo8dQ"},"outputs":[],"source":["epochs = 20  # maximum number of training epochs\n","folds = 10 # the number of folds for k-fold cross validation\n","n_repeats = 1  # the number of repeats for repeated k-fold cross validation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"42lcKDKuqv8m"},"outputs":[],"source":["def get_GC_generators(GC_train_index, GC_test_index, graph_labels, batch_size):\n","    GC_train_gen = generator.flow(\n","       # GC_train_index, targets=graph_labels.iloc[GC_train_index].values, batch_size=batch_size\n","       GC_train_index, targets=graph_labels[GC_train_index], batch_size=batch_size\n","    )\n","    GC_test_gen = generator.flow(\n","       # GC_test_index, targets=graph_labels.iloc[GC_test_index].values, batch_size=batch_size\n","       GC_test_index, targets=graph_labels[GC_test_index], batch_size=batch_size\n","    )\n","\n","    return GC_train_gen, GC_test_gen"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"70qNLVoTocTH","outputId":"cbf579e5-97c2-4b6a-a0a0-39c3f6d0e104","executionInfo":{"status":"ok","timestamp":1648127007902,"user_tz":0,"elapsed":509361,"user":{"displayName":"X Y","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05199952050475594564"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Training and evaluating on fold 1 out of 2...\n","Epoch 1/2\n","7500/7500 [==============================] - 67s 9ms/step - loss: 0.6192 - val_loss: 0.3764\n","Epoch 2/2\n","7500/7500 [==============================] - 68s 9ms/step - loss: 0.2391 - val_loss: 0.0807\n","7500/7500 [==============================] - 32s 4ms/step - loss: 0.0807\n","Training and evaluating on fold 2 out of 2...\n","Epoch 1/2\n","7500/7500 [==============================] - 68s 9ms/step - loss: 0.6242 - val_loss: 0.3942\n","Epoch 2/2\n","7500/7500 [==============================] - 68s 9ms/step - loss: 0.2104 - val_loss: 0.0792\n","7500/7500 [==============================] - 32s 4ms/step - loss: 0.0792\n"]}],"source":["test_accs2 = []\n","alltests = []\n","allpredictions = []\n","\n","cv = KFold(n_splits=folds, random_state=1, shuffle=True)\n","f = 1\n","for train_index, test_index in cv.split(AllLabels, AllLabels):\n","    print(f\"Training and evaluating on fold {f} out of {folds * n_repeats}...\")\n","    train_gen2, test_gen2 = get_GC_generators(\n","        train_index, test_index, AllLabels, batch_size=1\n","    )\n","\n","    gnnmodel = GCN(generator)\n","    gnnmodel.compile(optimizer=Adam(learning_rate=0.00005), loss=categorical_crossentropy)\n","    history = train_fold(gnnmodel, train_gen2, test_gen2, epochs)\n","    alltests.append(history[2])\n","    allpredictions.append(history[3])\n","    test_accs2.append(history[1])\n","    f +=1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XOF6I29IexGt"},"outputs":[],"source":["predictions = []\n","for sublist in allpredictions:\n","    for item in sublist:      \n","        predictions.append(int(np.argmax(item)))\n","\n","\n","tests = []\n","for sublist in alltests:\n","    for item2 in sublist:\n","        tests.append(int(np.argmax(item2)))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1648127951503,"user":{"displayName":"X Y","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05199952050475594564"},"user_tz":0},"id":"ngOkE__HncJT","outputId":"eb0cf73b-58fa-4301-dd78-783f402b200a"},"outputs":[{"output_type":"stream","name":"stdout","text":["2\n","[array([[1, 0, 0],\n","       [1, 0, 0],\n","       [1, 0, 0],\n","       ...,\n","       [0, 0, 1],\n","       [0, 0, 1],\n","       [0, 0, 1]]), array([[1, 0, 0],\n","       [1, 0, 0],\n","       [1, 0, 0],\n","       ...,\n","       [0, 0, 1],\n","       [0, 0, 1],\n","       [0, 0, 1]])]\n"]}],"source":["print(int(np.argmax(item)))\n","print(alltests)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PuZ05-9HfJk0"},"outputs":[],"source":["allrepo=classification_report(tests, predictions, output_dict=True)\n","print(allrepo)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vbRDRxKSfWvi"},"outputs":[],"source":["df = pd.DataFrame(allrepo).transpose()\n","df.to_latex('GNN-3domains.tex')\n"]},{"cell_type":"code","source":["!mv GNN-3domains.tex \"/content/drive/MyDrive/Colab Notebooks/GECCO-2022/\""],"metadata":{"id":"71RIhRzYjQC8"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M9x9UAOYywO3"},"outputs":[],"source":["sg.utils.plot_history(history)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"317k0YaDnww4"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","X_train,X_test, y_train,y_test = train_test_split(X, y, test_size=0.2, random_state=13)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"NX-SG-Domains-AS.ipynb","provenance":[{"file_id":"1ASqlLwWY4Sx_8BcF_16dZmy93qipMcWn","timestamp":1648039832216},{"file_id":"1LGD43ZOIYEDaEAJMYS4hnc2JyANPTQva","timestamp":1647696862725},{"file_id":"1JwzTXkasJOEvaJfCG5LvWDrQMXof0eps","timestamp":1647426496721}],"mount_file_id":"1WLxIYqL7Vmu39aqTXlr0SJU7ciECUJFg","authorship_tag":"ABX9TyNeREvDT8OJ4nam0zpNr63k"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}